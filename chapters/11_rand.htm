<?xml version="1.0" encoding="UTF-8" standalone="no"?><html xmlns="http://www.w3.org/1999/xhtml"><head>
<title>Fooled By Randomness</title>
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="http://www.w3.org/1999/xhtml; charset=utf-8" http-equiv="Content-Type"/>
<meta name="Adept.resource" value="urn:uuid:5357f980-a6ae-4120-b5a6-e0821e7ce051"/></head>
<body><div id="c11">
<p class="cn">Eleven</p>
<p class="atx">•</p>
<p class="ct">RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND</p>
<div class="blockquote"><div class="div"><p class="cepi"><em>On the difficulty of thinking of your vacation as a linear combination of Paris and the Bahamas. Nero Tulip may never ski in the Alps again. Do not ask bureaucrats too many questions. A Brain Made in Brooklyn. We need Napoleon. Scientists bowing to the King of Sweden. A little more on journalistic pollution. Why you may be dead by now.</em> </p></div></div>
<br/>
<p class="imp"><a id="c11.1"/><small>PARIS OR THE BAHAMAS?</small></p>
<p class="tx1"><span class="ic">Y</span>ou have two options for your next brief vacation in March. The first is to fly to Paris; the second is to go to the Caribbean. You expressed indifference between the two options; your spouse will tip the decision one way or the other. Two distinct and separate images come to you when you think of the possibilities. In the first one, you see yourself standing at the Musée d’Orsay in front of some Pissaro painting depicting a cloudy sky—the gray Parisian wintry sky. You are carrying an umbrella under your arm. In the second image, you are lying on a towel with a stack of books by your favorite authors next to you (Tom Clancy and Ammianus Marcellinus), and an obsequious waiter serving you a banana daiquiri. You know that the two states are mutually exclusive (you can only be in one place at one time), but exhaustive (there is a 100% probability that you will be in one of them). They are equiprobable, with, in your opinion, 50% probability assigned to each.</p>
<p class="tx">You derive great pleasure thinking about your vacation; it motivates you and makes your daily commute more bearable. But the adequate way to visualize yourself, according to rational behavior under uncertainty, is 50% in one of the vacation spots and 50% in the other—what is mathematically called a <em>linear combination</em> of the two states. Can your brain handle that? How desirable would it be to have your feet in the Caribbean waters and your head exposed to the Parisian rain? Our brain can properly handle one and only one state at once—unless you have personality troubles of a deeply pathological nature. Now try to imagine an 85%/15% combination. Any luck?</p>
<p class="tx">Consider a bet you make with a colleague for the amount of $1,000, which, in your opinion, is exactly fair. Tomorrow night you will have zero or $2,000 in your pocket, each with a 50% probability. In purely mathematical terms, the fair value of a bet is the linear combination of the states, here called the <em>mathematical expectation,</em> i.e., the probabilities of each payoff multiplied by the dollar values at stake (50% multiplied by 0 and 50% multiplied by $2,000 =$1,000). Can you <em>imagine</em> (that is visualize, not compute mathematically) the value being $1,000? We can conjure up one <em>and only one</em> state at a given time, i.e., either 0 or $2,000. Left to our own devices, we are likely to bet in an irrational way, as one of the states would dominate the picture—the fear of ending with nothing or the excitement of an extra $1,000.</p>
<p class="imp"><a id="c11.2"/><small>SOME ARCHITECTURAL CONSIDERATIONS</small></p>
<p class="tx1">Time to reveal Nero’s secret. It was a black swan. He was then thirty-five. Although prewar buildings in New York can have a pleasant front, their architecture seen from the back offers a stark contrast by being completely bland. The doctor’s examination room had a window overlooking the backyard of one such Upper East Side street, and Nero will always remember how bland that backyard was in comparison with the front, even if he were to live another half century. He will always remember the view of the ugly pink backyard from the leaden window panes, and the medical diploma on the wall that he read a dozen times as he was waiting for the doctor to come into the room (half an eternity, for Nero suspected that something was wrong). The news was then delivered (grave voice), “I have some . . . I got the pathology report . . . It’s . . . It is not as bad as it sounds . . . It’s . . . It’scancer.” The declaration caused his body to be hit by an electric discharge, running through his back down to his knees. Nero tried to yell “What?” but no sound came out of his mouth. What scared him was not so much the news as the sight of the doctor. Somehow the news reached his body before his mind. There was too much fear in the doctor’s eyes and Nero immediately suspected that the news was even worse than what he was being told (it was).</p>
<p class="tx">The night of the diagnosis, at the medical library where he sat, drenched wet from walking for hours in the rain without noticing it and making a puddle of water around him (he was yelled at by an attendant but could not concentrate on what she was saying so she shrugged her shoulders and walked away); later he read the sentence “72% 5-year actuarially adjusted survival rate.” It meant that 72 people out of 100 make it. It takes between three and five years for the body without clinical manifestations of the disease for the patient to be pronounced cured (closer to three at his age). He then felt in his guts quite certain that he was going to make it.</p>
<p class="tx">Now the reader might wonder about the mathematical difference between a 28% chance of death and a 72% chance of survival over the next five years. Clearly, there is none, but we are not made for mathematics. In Nero’s mind a 28% chance of death meant the image of himself dead, and thoughts of the cumbersome details of his funeral. A 72% chance of survival put him in a cheerful mood; his mind was planning the result of a cured Nero skiing in the Alps. At no point during his ordeal did Nero think of himself as 72% alive and 28% dead.</p>
<p class="tx">Just as Nero cannot “think” in complicated shades, consumers consider a 75% fat-free hamburger to be different from a 25% fat one. Likewise with statistical significance. Even specialists tend to infer too fast from data in accepting or rejecting things. Recall the dentist whose emotional well-being depends on the recent performance of his portfolio. Why? Because as we will see, rule-determined behavior does not require nuances. Either you kill your neighbor or you don’t. Intermediate sentiments (leading, say, to only half his killing) are either useless or downright dangerous when you do things. The emotional apparatus that jolts us into action does not understand such nuances—it is not efficient to understand things. The rest of this chapter will rapidly illustrate some manifestations of such blindness, with a cursory exposition of the research in that area (only what connects to the topics in this book).</p>
<p class="imp"><a id="c11.3"/><small>BEWARE THE PHILOSOPHER BUREAUCRAT</small></p>
<p class="tx1">For a long time we had the wrong product specifications when we thought of ourselves. We humans have been under the belief that we were endowed with a beautiful machine for thinking and understanding things. However, among the factory specifications for us is the lack of awareness of the true factory specifications (why complicate things?). The problem with thinking is that it causes you to develop illusions. And thinking may be such a waste of energy! Who needs it!</p>
<p class="tx">Consider that you are standing in front of a government clerk in a heavily socialist country where being a bureaucrat is held to be what respectable people do for a living. You are there to get your papers stamped by him so you can export some of their lovely chocolate candies to the New Jersey area, where you think the local population would have a great taste for them. What do you think his function is? Do you think for a minute that he cares about the general economic theory behind the transaction? His job is just to verify that you have the twelve or so signatures from the right departments, true/false; then stamp your papers and let you go. General considerations of economic growth or balance of trade are none of his interests. In fact you are lucky that he doesn’t spend any time meditating about these things: Consider how long the procedure would take if he had to solve balance of trade equations. He just has a rulebook and, over a career spanning forty to forty-five years, he will just stamp documents, be mildly rude, and go home to drink nonpasteurized beer and watch soccer games. If you gave him Paul Krugman’s book on international economics he would either sell it in the black market or give it to his nephew.</p>
<p class="tx">Accordingly, rules have their value. We just follow them not because they are the best but because they are useful and they save time and effort. Consider that those who started theorizing upon seeing a tiger on whether the tiger was of this or that taxonomic variety, and the degree of danger it represented, ended up being eaten by it. Others who just ran away at the smallest presumption and were not slowed down by the smallest amount of thinking ended up either outchasing the tiger or outchasing their cousin who ended up being eaten by it.</p>
<p class="atx"><a id="c11.3.1"/><em>Satisficing</em> </p>
<p class="tx1">It is a fact that our brains would not be able to operate without such shortcuts. The first thinker who figured it out was Herbert Simon, an interesting fellow in intellectual history. He started out as a political scientist (but he was a formal thinker, not the literary variety of political scientists who write about Afghanistan in <em>Foreign Affairs</em>); he was an artificial-intelligence pioneer, taught computer science and psychology, did research in cognitive science, philosophy, and applied mathematics, and received the Bank of Sweden Prize for Economics in honor of Alfred Nobel. His idea is that if we were to optimize at every step in life, then it would cost us an infinite amount of time and energy. Accordingly, there has to be in us an approximation process that stops somewhere. Clearly he got his intuitions from computer science—he spent his entire career at Carnegie-Mellon University in Pittsburgh, which has a reputation as a computer science center. “Satisficing” was his idea (the melding together of <em>satisfy</em> and <em>suffice</em>): You stop when you get a near-satisfactory solution. Otherwise it may take you an eternity to reach the smallest conclusion or perform the smallest act. We are therefore rational, but in a limited way: “boundedly rational.” He believed that our brains were a large optimizing machine that had built-in rules to stop somewhere.</p>
<p class="tx">Not quite so, perhaps. It may not be just a rough approximation. For two (initially) Israeli researchers on human nature, how we behave seemed to be a completely different process from the optimizing machine presented by Simon. The two sat down introspecting in Jerusalem looking at aspects of their own thinking, compared it to rational models, and noticed <em>qualitative</em> differences. Whenever they both seemed to make the same mistake of reasoning they ran empirical tests on subjects, mostly students, and discovered very surprising results on the relation between thinking and rationality. It is to their discovery that we turn next.</p>
<p class="imp"><a id="c11.4"/><small>FLAWED, NOT JUST IMPERFECT</small></p>
<p class="atx"><a id="c11.4.1"/><em>Kahneman and Tversky</em> </p>
<p class="tx1">Who has exerted the most influence on economic thinking over the past two centuries? No, it is not John Maynard Keynes, not Alfred Marshall, not Paul Samuelson, and certainly not Milton Friedman. The answer is two noneconomists: Daniel Kahneman and Amos Tversky, the two Israeli introspectors, and their specialty was to uncover areas where human beings are not endowed with rational probabilistic thinking and optimal behavior under uncertainty. Strangely, economists studied uncertainty for a long time and did not figure out much—if anything, they thought they knew something and were fooled by it. Aside from some penetrating minds like Keynes, Knight, and Shackle, economists did not even figure out that they had no clue about uncertainty—the discussions on risk by their idols show that <em>they did not know how much they did not know.</em> Psychologists, on the other hand, looked at the problem and came out with solid results. Note that, unlike economists, they conducted experiments, true controlled experiments of a repeatable nature, that can be done in Ulan Bator, Mongolia, tomorrow if necessary. Conventional economists do not have this luxury as they observe the past and make lengthy and mathematical comments, then bicker with each other about them.</p>
<p class="tx">Kahneman and Tversky went in a completely different direction than Simon and started figuring out rules in humans that did not make them rational—but things went beyond the shortcut. For them, these rules, which are called <em>heuristics,</em> were not merely a simplification of rational models, but were different in methodology and category. They called them “quick and dirty” heuristics. There is a dirty part: These shortcuts came with side effects, these effects being the biases, most of which I discussed previously throughout the text (such as the inability to accept anything abstract as risk). This started an empirical research tradition called the “heuristics and biases” tradition that attempted to catalogue them—it is impressive because of its empiricism and the experimental aspect of the methods used.</p>
<p class="tx">Since the Kahneman and Tversky results, an entire discipline called behavioral finance and economics has flourished. It is in open contradiction with the orthodox so-called neoclassical economics taught in business schools and economics departments under the normative names of efficient markets, rational expectations, and other such concepts. It is worth stopping, at this juncture, and discussing the distinction between normative and positive sciences. A normative science (clearly a self-contradictory concept) offers prescriptive teachings; it studies how things <em>should</em> be. Some economists, for example those of the efficient-market religion, believe that our studies should be based on the hypothesis that humans are rational and act rationally because it is the best thing for them to do (it is mathematically “optimal”). The opposite is a positive science, which is based on how people actually are observed to behave. In spite of economists’ envy of physicists, physics is an inherently positive science while economics, particularly microeconomics and financial economics, is predominantly a normative one. Normative economics is like religion without the aesthetics.</p>
<p class="tx">Note that the experimental aspect of the research implies that Daniel Kahneman and the experimental ponytailed economist Vernon Smith were the first true scientists ever to bow in front of the Swedish king for the economics prize, something that should give credibility to the Nobel academy, particularly if, like many, one takes Daniel Kahneman far more seriously than a collection of serious-looking (and very human, hence fallible) Swedes. There is another hint of the scientific firmness of this research: It is extremely readable for someone outside of psychology, unlike papers in conventional economics and finance that even people in the field have difficulty reading (as the discussions are jargon-laden and heavily mathematical to give the illusion of science). A motivated reader can get concentrated in four volumes the collection of the major heuristics and biases papers.</p>
<p class="tx">Economists were not at the time very interested in hearing these stories of irrationality: <em>Homo economicus</em> as we said is a normative concept. While they could easily buy the “Simon” argument that we are not perfectly rational and that life implies approximations, particularly when the stakes are not large enough, they were not willing to accept that people were flawed rather than imperfect. But they are. Kahneman and Tversky showed that these biases do not disappear when there are incentives, which means that they are not necessarily cost saving. They were a different form of reasoning, and one where the probabilistic reasoning was weak.</p>
<p class="imp"><a id="c11.5"/><small>WHERE IS NAPOLEON WHEN WE NEED HIM?</small></p>
<p class="tx1">If your mind operates by series of different disconnected rules, these may not be necessarily consistent with each other, and if they may still do the job <em>locally,</em> they will not necessarily do so <em>globally.</em> Consider them stored as a rulebook of sorts. Your reaction will depend on which page of the book you open to at any point in time. I will illustrate it with another socialist example.</p>
<p class="tx">After the collapse of the Soviet Union, Western businesspeople involved in what became Russia discovered an annoying (or entertaining) fact about the legal system: It had conflicting and contradictory laws. It just depended on which chapter you looked up. I don’t know whether the Russians wanted it as a prank (after all, they lived long, humorless years of oppression) but the confusion led to situations where someone had to violate a law to comply with another. I have to say that lawyers are quite dull people to talk to; talking to a dull lawyer who speaks broken English with a strong accent and vodka breath can be quite straining—so you give up. This spaghetti legal system came from the piecewise development of the rules: You add a law here and there and the situation is too complicated as there is no central system that is consulted every time to ensure compatibility of all the parts together. Napoleon faced a similar situation in France and remedied it by setting up a top-down code of law that aimed to dictate a full logical consistency. The problem with us humans is not so much that no Napoleon has showed up so far to dynamite the old structure then reengineer our minds like a big central program; it is that our minds are far more complicated than just a system of laws, and the requirement for efficiency is far greater.</p>
<p class="tx">Consider that your brain reacts differently to the same situation depending on which chapter you open to. The absence of a central processing system makes us engage in decisions that can be in conflict with each other. You may prefer apples to oranges, oranges to pears, but pears to apples—it depends on how the choices are presented to you. The fact that your mind cannot retain and use everything you know at once is the cause of such biases. One central aspect of a heuristic is that it is blind to reasoning.</p>
<br/>
<p class="epi"><a id="c11.5.1"/><em>“I’m As Good As My Last Trade” and Other Heuristics</em> </p>
<p class="tx1">There exist plenty of different catalogues of these heuristics in the literature (many of them overlapping); the object of this discussion is to provide the intuition behind their formation rather than list them. For a long time we traders were totally ignorant of the behavioral research and saw situations where there was with strange regularity a wedge between the simple probabilistic reasoning and people’s perception of things. We gave them names such as the “I’m as good as my last trade” effect, the “sound-bite effect,” the “Monday morning quarterback” heuristic, and the “It was obvious after the fact” effect. It was both vindicating for traders’ pride and disappointing to discover that they existed in the heuristics literature as the “anchoring,” the “affect heuristic,” and the “hindsight bias” (it makes us feel that trading is true, experimental scientific research). The correspondence between the two worlds is shown in Table 11.1.</p>
<p class="tx">I start with the “I’m as good as my last trade” heuristic (or the “loss of perspective” bias)—the fact that the counter is reset at zero and you start a new day or month from scratch, whether it is your accountant who does it or your own mind. This is the most significant distortion and the one that carries the most consequences. In order to be able to put things in general context, you do not have everything you know in your mind at all times, so you retrieve the knowledge that you require at any given time in a piecemeal fashion, which puts these retrieved knowledge chunks in their local context. This means that you have an arbitrary reference point and react to differences from that point, forgetting that you are only looking at the differences from that particular perspective of the local context, not the absolutes.</p>
<p class="atx">Table 11.1 Trader and Scientific Approach</p>
<p class="atx"><img alt="image" src="images/Tale_9781588367679_epub_007_r1.jpg"/></p>
<br/>
<p class="tx">There is the well-known trader maxim “life is incremental.” Consider that as an investor you examine your performance like the dentist in <a href="Tale_9781588367679_epub_c03_r1.htm">Chapter 3</a>, at some set interval. What do you look at: your monthly, your daily, your life-to-date, or your hourly performance? You can have a good month and a bad day. Which period should dominate?</p>
<p class="tx">When you take a gamble, do you say: “My net worth will end up at $99,000 or $101,500 after the gamble” or do you say “I lose $1,000 or make $1,500?” Your attitude toward the risks and rewards of the gamble will vary according to whether you look at your net worth or changes in it. But in fact in real life you will be put in situations where you will only look at your <em>changes.</em> The fact that the losses hurt more than the gains, and <em>differently,</em> makes your accumulated performance, that is, your total wealth, less relevant than the last change in it.</p>
<p class="tx">This dependence on the local rather than the global status (coupled with the effect of the losses hitting harder than the gains) has an impact on your perception of well-being. Say you get a windfall profit of $1 million. The next month you lose $300,000. You adjust to a given wealth (unless of course you are very poor) so the following loss would hurt you emotionally, something that would not have taken place if you received the net amount of $700,000 in one block, or, better, two sums of $350,000 each. In addition, it is easier for your brain to detect differences rather than absolutes, hence rich or poor will be (above the minimum level) in relation to something else (remember Marc and Janet). Now, when something is <em>in relation</em> to something else, that something else can be manipulated. Psychologists call this effect of comparing to a given reference <em>anchoring.</em> If we take it to its logical limit we would realize that, because of this resetting, wealth itself does not really make one happy (above, of course, some subsistence level); but positive changes in wealth may, especially if they come as “steady” increases. More on that later with my discussion of option blindness.</p>
<p class="tx">Other aspects of anchoring. Given that you may use two different anchors in the same situation, the way you act depends on so little. When people are asked to estimate a number, they will position it with respect to a number they have in mind or one they just heard, so “big” or “small” will be comparative. Kahneman and Tversky asked subjects to estimate the proportion of African countries in the United Nations after making them consciously pull a random number between 0 and 100 (they knew it was a random number). People guessed in relation to that number, which they used as anchor: Those who randomized a high number guessed higher than those who randomized a low one. This morning I did my bit of anecdotal empiricism and asked the hotel concierge how long it takes to go to the airport. “40 minutes?” I asked. “About 35,” he answered. Then I asked the lady at the reception if the journey was 20 minutes. “No, about 25,” she answered. I timed the trip: 31 minutes.</p>
<p class="tx">This anchoring to a number is the reason people do not react to their total accumulated wealth, but to differences of wealth from whatever number they are currently anchored to. This is the major conflict with economic theory, as according to economists, someone with $1 million in the bank would be more satisfied than if he had half a million. But we saw John reaching $1 million having had a total of $10 million; he was happier when he only had half a million (starting at nothing) than where we left him in <a href="Tale_9781588367679_epub_c01_r1.htm">Chapter 1</a>. Also recall the dentist whose emotions depended on how frequently he checked his portfolio.</p>
<p class="atx"><a id="c11.5.2"/><em>Degree in a Fortune Cookie</em> </p>
<p class="tx1">I used to attend a health club in the middle of the day and chat with an interesting Eastern European fellow with two Ph.D. degrees, one in physics (statistical no less), the other in finance. He worked for a trading house and was obsessed with the anecdotal aspects of the markets. He once asked me doggedly what I thought the stock market would do that day. Clearly I gave him a social answer of the kind “I don’t know, perhaps lower”—quite possibly the opposite answer to what I would have given him had he asked me an hour earlier. The next day he showed great alarm upon seeing me. He went on and on discussing my credibility and wondering how I could be so wrong in my “predictions,” since the market went up subsequently. The man was able to derive conclusions about my ability to predict and my “credibility” with a single observation. Now, if I went to the phone and called him and disguised my voice and said, “Hello, this is Doktorr Talebski from the Academy of Lodz and I have an interrresting prrroblem,” then presented the issue as a statistical puzzle, he would laugh at me. “Doktorr Talevski, did you get your degree in a fortune cookie?” Why is it so?</p>
<p class="tx">Clearly there are two problems. First, the quant did not use his statistical brain when making the inference, but a different one. Second, he made the mistake of overstating the importance of small samples (in this case just one single observation, the worst possible inferential mistake a person can make). Mathematicians tend to make egregious mathematical mistakes outside of their theoretical habitat. When Tversky and Kahneman sampled mathematical psychologists, some of whom were authors of statistical textbooks, they were puzzled by their errors. “Respondents put too much confidence in the result of small samples and their statistical judgment showed little sensitivity to sample size.”The puzzling aspect is that not only <em>should</em> they have known better, “they <em>did</em> know better.” And yet . . .</p>
<p class="tx">I will next list a few more heuristics. (1) The <em>availability</em> heuristic, which we saw in <a href="Tale_9781588367679_epub_c03_r1.htm">Chapter 3</a> with the earthquake in California deemed more likely than catastrophe in the entire country, or death from terrorism being more “likely” than death from all possible sources (including terrorism). It corresponds to the practice of estimating the frequency of an event according to the ease with which instances of the event can be recalled. (2) The <em>representativeness</em> heuristic: gauging the probability that a person belongs to a particular social group by assessing how similar the person’s characteristics are to the “typical” group member’s. A feminist-style philosophy student is deemed more likely to be a feminist bank teller than to be just a bank teller. This problem is known as the “Linda problem” (the feminist’s name was Linda) and has caused plenty of academic ink to flow (some of the people engaged in the “rationality debate” believe that Kahneman and Tversky are putting highly normative demands on us humans). (3) The <em>simulation</em> heuristic: the ease of mentally undoing an event—playing the alternative scenario. It corresponds to counterfactual thinking: Imagine what might have happened had you not missed your train (or how rich you’d be today had you liquidated your portfolio at the height of the NASDAQ bubble). (4) We discussed in <a href="Tale_9781588367679_epub_c03_r1.htm">Chapter 3</a> the <em>affect</em> heuristic: What emotions are elicited by events determine their probability in your mind.</p>
<p class="atx"><a id="c11.5.3"/><em>Two Systems of Reasoning</em> </p>
<p class="tx1">Later research refines the problem as follows: There are two possible ways for us to reason, the heuristics being part of one—rationality being part of the other. Recall the colleague who used a different brain in the classroom than the one in real life in <a href="Tale_9781588367679_epub_c02_r1.htm">Chapter 2</a>. Didn’t you wonder why the person you think knows physics so well cannot apply the basic laws of physics by driving well? Researchers divide the activities of our mind into the following two polarized parts, called System 1 and System 2.</p>
<p class="tx"><em>System 1</em> is effortless, automatic, associative, rapid, parallel process, opaque (i.e., we are not aware of using it), emotional, concrete, specific, social, and personalized.</p>
<p class="tx"><em>System 2</em> is effortful, controlled, deductive, slow, serial, self-aware, neutral, abstract, sets, asocial, and depersonalized.</p>
<p class="tx">I have always believed that professional option traders and market makers by dint of practicing their probabilistic game build an innate probabilistic machine that is far more developed than the rest of the population—even that of probabilists. I found a confirmation of that as researchers in the heuristics and biases tradition believe that System 1 can be impacted by experience and integrate elements from System 2. For instance, when you learn to play chess, you use System 2. After a while things become intuitive and you are able to gauge the relative strength of an opponent by glancing at the board.</p>
<p class="tx">Next I introduce the evolutionary psychology point of view.</p>
<p class="imp"><a id="c11.6"/><small>WHY WE DON’T MARRY THE FIRST DATE</small></p>
<p class="tx1">Another branch of research, called evolutionary psychology, developed a completely different approach to the same problem. It operates in parallel, creating some bitter but not too worrisome academic debates. These evolutionary psychologists agree with the Kahneman-Tversky school that people have difficulties with standard probabilistic reasoning. However, they believe that the reason lies in the way things are presented to us in the current environment. To them, we are optimized for a set of probabilistic reasoning, but in a different environment than the one prevailing today. The statement “Our brains are made for fitness not for truth” by the scientific intellectual Steven Pinker, the public spokesmen of that school, summarizes it all. They agree that our brains are not made for understanding things but think that they are not biased, or only biased because we do not use them in their real habitat.</p>
<p class="tx">Strangely, the Kahneman-Tversky school of researchers did not incur any credible resistance from the opinions of the economists of the time (the general credibility of conventional economists has always been so low that almost nobody in science or in the real world ever pays attention to them). No, instead the challenge came from the sociobiologists—and the center of the disagreement lies in their belief in using evolutionary theory as a backbone for our understanding of human nature. While this caused a fierce scientific dispute, I will have to say that they agree on the significant part as far as this book is concerned: (1) We do not <em>think</em> when making choices but use heuristics; (2) We make serious probabilistic mistakes in today’s world<em>—whatever the true reason.</em> Note that the split even covers the new economics: Just as we have a scientific branch of economics coming out of the Kahneman and Tversky tradition (behavioral economics), there is another scientific branch of economics coming out of evolutionary psychology, with the caveman economics approach followed by such researchers as the economist-biologist Terry Burnham, coauthor of the very readable <em>Mean Genes.</em> </p>
<p class="atx"><a id="c11.6.1"/><em>Our Natural Habitat</em> </p>
<p class="tx1">I will not delve too deeply into amateur evolutionary theory to probe at the reasons (besides, in spite of having spent some time in libraries I feel that I am truly an amateur in the subject matter). Clearly, the environment for which we have built our endowment is not the one that prevails today. I have not told too many of my colleagues that their decision making contains some lingering habits of cavemen—but when markets experience an abrupt move, I experience the same rush of adrenaline as if a leopard were seen prowling near my trading desk. Some of my colleagues who break telephone handles upon losing money might be even closer in their psychological makeup to our common origin.</p>
<p class="tx">This might be a platitude to those who frequent the Greek and Latin classics, but we never fail to be surprised when noticing that people a couple of dozen centuries removed from us can exhibit similar sensibility and feelings. What used to strike me as a child upon visiting museums is that ancient Greek statues exhibit men with traits indistinguishable from ours (only more harmonious and aristocratic). I was so wrong to believe that 2,200 years was a long time. Proust wrote frequently about the surprise people have when coming across emotions in Homeric heroes that are similar to those we experience today. By genetic standards, these Homeric heroes of thirty centuries ago in all likelihood have the exact identical makeup as the pudgy middle-aged man you see schlepping groceries in the parking lot. More than that. In fact, we are truly identical to the man who perhaps eighty centuries ago started being called “civilized,” in that strip of land stretching from southeastern Syria to southwestern Mesopotamia.</p>
<p class="tx">What is our natural habitat? By natural habitat, I mean the environment in which we reproduced the most, the one in which we spent the highest number of generations. The consensus among anthropologists is that we have been around as a separate species for 130,000 years, most of which were spent in the African savannah. But we do not have to go back that far in history to get the point. Imagine life in an early urban settlement, in Middle-Town, Fertile Crescent, only about 3,000 years ago—surely modern times from a genetic standpoint. Information is limited by the physical means of its transmission; one cannot travel fast, hence information will come from faraway places in concise batches. Traveling is a nuisance fraught with all manner of physical danger; you will settle within a narrow radius of where you were born unless famine or some invading uncivilized tribe dislodges you and your relatives from your happy settlement. The number of people you would get to know in a lifetime will be small. Should a crime be committed, it will be easy to gauge the evidence of guilt within the small number of possible suspects. If you are unjustly convicted of a crime, you will argue in simple terms, propounding simple evidence like “I was not there as I was praying in the temple of Baal and was seen at dusk by the high priest” and add that Obedshemesh, son of Sahar, was more likely to be guilty because he had more to gain from the crime. Your life would be simple, hence your space of <em>probabilities</em> would be narrow.</p>
<p class="tx">The real problem is, as I have mentioned, that such a natural habitat does not include much information. An efficient computation of the odds was never necessary until very recently. This also explains why we had to wait until the emergence of the gambling literature to see the growth of the mathematics of probability. Popular belief holds that the religious backdrop of the first and second millennia blocked the growth of tools that hint at absence of determinism, and caused the delays in probability research. The idea is extremely dubious; we simply did not compute probabilities because we did not <em>dare</em> to? Surely the reason is rather because we did not <em>need</em> to. Much of our problem comes from the fact that we have evolved out of such a habitat faster, much faster, than our genes. Even worse, our genes have not changed at all.</p>
<p class="atx"><a id="c11.6.2"/><em>Fast and Frugal</em> </p>
<p class="tx1">Evolutionary theorists agree that brainwork depends on how the subject is presented and the frame offered—and they can be contradictory in their results. We detect cheaters with a different part of our brain than the one we draw on to solve logical problems. People can make incoherent choices because the brain works in the form of small partial jobs. Those heuristics that we said were “quick and dirty” to the psychologists are “fast and frugal” to the evolutionary psychologists. Not only that, but some thinkers, like the cognitive scientist Gerd Gigerenzer, seem to have obsessively taken the other side of the trade from Kahneman and Tversky; his work and that of his associates at the ABC Group (Adaptive Behavior and Cognition) intend to show that we are rational and that evolution produces a form of rationality he calls “ecological rationality.” They believe that not only are we hard-wired for <em>optimizing probabilistic</em> behavior in situations like mate selection (how many people of the opposite sex do you need to meet before pulling the trigger?), or choosing a meal, but we are also so wired for stock selection and that we do it appropriately if the stocks are presented to us in the correct manner.</p>
<p class="tx">In fact, Gigerenzer agrees that we do not understand probability (too abstract), but we react rather well to frequencies (less abstract): According to him, some problems that normally would cause us to make a mistake disappear when phrased in terms of percentages.</p>
<p class="tx">According to these researchers, while we may like to think of our brain as a central processing system, with top-down features, an analogy to the Swiss Army knife (with its small specific tools) seems to be in order. How? The psychologists’ framework is built around the distinction between the domain-specific and domain-general adaptations. A domain-specific adaptation is something that is meant to solve a very precise task (as opposed to domain-general ones that are meant to solve global ones). While these are easy to understand and accept for physiological adaptations (i.e., a giraffe’s neck helps in reaching food or an animal’s colors in providing camouflage), people have had difficulties accepting why these apply to our mind in the same manner.</p>
<p class="tx">Our brain functions by “modules.” An interesting aspect of modularity is that we may use different modules for different instances of the <em>same</em> problem, depending on the framework in which it is presented—as discussed in the notes to this section. One of the attributes of a module is its “encapsulation,” i.e., we cannot interfere with its functioning, as we are not aware of using it. The most striking module is used when we try to find a cheater. Expressed in purely logical form (though with extreme clarity), a given quiz is only solved by 15% of the people to whom it is given. Now, the same quiz expressed in a manner that aims at uncovering a cheater, almost everyone gets it.</p>
<p class="atx"><a id="c11.6.3"/><em>Neurobiologists Too</em> </p>
<p class="tx1">Neurobiologists also have their side of the story. They believe (roughly) that we have three brains: The very old one, the reptilian brain that dictates heartbeat and that we share with all animals; the limbic brain center of emotions that we share with mammals; and the neocortex, or cognitive brain, that distinguishes primates and humans (note that even institutional investors seem to have a neocortex). While that theory of the Triune brain shows some over-simplification (particularly when handled by journalists), it seems to provide a framework for the analysis of brain functions.</p>
<p class="tx">Although it is very difficult to figure out which part of the brain does what exactly, neuroscientists have been doing some environment mapping in the brain by, say, taking a patient whose brain is damaged in one single spot (say, by a tumor or an injury deemed to be local) and deducing by elimination the function performed by such part of the anatomy. Other methods include brain imaging and electric simulations to specific areas. Many researchers outside of neurobiology, like the philosopher and cognitive scientist Jerry Fodor (who pioneered the notion of modularity) remain skeptical about the quality of the knowledge that we can uncover by examining the physical properties of the brain, be it only on account of the complicated interactions of the single parts (with corresponding nonlinearities). The mathematician and cognitive scientist David Marr, who pioneered the field of object recognition, made the apt remark that one does not learn how birds fly by studying feathers but rather by studying aerodynamics. I will present the theses of two watershed works presented in readable books, Damasio’s <em>Descartes’ Error</em> and LeDoux’s <em>Emotional Brain.</em> </p>
<p class="tx"><em>Descartes’ Error</em> presents a very simple thesis: You perform a surgical ablation on a piece of someone’s brain (say, to remove a tumor and tissue around it) with the sole resulting effect of an inability to register emotions, nothing else (the IQ and every other faculty remain the same). What you have done is a controlled experiment to separate someone’s intelligence from his emotions. Now you have a purely rational human being unencumbered with feelings and emotions. Let’s watch: Damasio reported that the purely unemotional man was incapable of making the simplest decision. He could not get out of bed in the morning, and frittered away his days fruitlessly weighing decisions. Shock! This flies in the face of everything one would have expected: One cannot make a decision without emotion. Now, mathematics gives the same answer: If one were to perform an optimizing operation across a large collection of variables, even with a brain as large as ours, it would take a very long time to decide on the simplest of tasks. So we need a shortcut; emotions are there to prevent us from temporizing. Does it remind you of Herbert Simon’s idea? It seems that the emotions are the ones doing the job. Psychologists call them “lubricants of reason.”</p>
<p class="tx">Joseph LeDoux’s theory about the role of emotions in behavior is even more potent: Emotions affect one’s thinking. He figured out that much of the connections from the emotional systems to the cognitive systems are stronger than connections from the cognitive systems to the emotional systems. The implication is that we feel emotions (limbic brain) then find an explanation (neocortex). As we saw with Claparède’s discovery, much of the opinions and assessments that we have concerning risks may be the simple result of emotions.</p>
<p class="atx"><a id="c11.6.4"/><em>Kafka in a Courtroom</em> </p>
<p class="tx1">The O. J. Simpson trial provides an example of how our modern society is ruled by probability (because of the explosion in information), while important decisions are made without the smallest regard for its basic laws. We are capable of sending a spacecraft to Mars, but we are incapable of having criminal trials managed by the basic laws of probability—yet evidence is clearly a probabilistic notion. I remember buying a book on probability at a Borders Books chain bookstore only a short distance from the Los Angeles courthouse where the “trial of the century” was taking place—another book that crystallized the highly sophisticated quantitative knowledge in the field. How could such a leap in knowledge elude lawyers and jurors only a few miles away?</p>
<p class="tx">People who are as close to being criminal as probability laws can allow us to infer (that is, with a confidence that exceeds the <em>shadow of a doubt</em>) are walking free because of our misunderstanding of basic concepts of the odds. Equally, you could be convicted for a crime you never committed, again owing to a poor reading of probability—for we still cannot have a court of law properly compute the joint probability of events (the probability of two events taking place at the same time). I was in a dealing room with a TV set turned on when I saw one of the lawyers arguing that there were at least four people in Los Angeles capable of carrying O. J. Simpson’s DNA characteristics (thus ignoring the joint set of events—we will see how in the next paragraph). I then switched off the television set in disgust, causing an uproar among the traders. I was under the impression until then that sophistry had been eliminated from legal cases thanks to the high standards of republican Rome. Worse, one Harvard lawyer used the specious argument that only 10% of men who brutalize their wives go on to murder them, which is a probability unconditional on the murder (whether the statement was made out of a warped notion of advocacy, pure malice, or ignorance is immaterial). Isn’t the law devoted to the truth? The correct way to look at it is to determine the percentage of murder cases where women were killed by their husbands <em>and</em> had previously been battered by them (that is, 50%)—for we are dealing with what is called <em>conditional</em> probabilities; the probability that O. J. killed his wife <em>conditional</em> on the information of her having been killed, rather than the <em>unconditional</em> probability of O. J. killing his wife. How can we expect the untrained person to understand randomness when a Harvard professor who deals and teaches the concept of probabilistic evidence can make such an incorrect statement?</p>
<p class="tx">More particularly, where jurors (and lawyers) tend to make mistakes, along with the rest of us, is in the notion of joint probability. They do not realize that evidence compounds. The probability of my being diagnosed with respiratory tract cancer and being run over by a pink Cadillac in the same year, assuming each one of them is 1/100,000, becomes 1/10,000,000,000—by multiplying the two (obviously independent) events. Arguing that O. J. Simpson had 1/500,000 chance of not being the killer from the blood standpoint (remember the lawyers used the sophistry that there were four people with such blood types walking around Los Angeles) and adding to it the fact that he was the husband of the person and that there was additional evidence, then (owing to the compounding effect) the odds against him rise to several trillion trillion.</p>
<p class="tx">“Sophisticated” people make worse mistakes. I can surprise people by saying that the probability of the joint event is lower than either. Recall the availability heuristic: with the Linda problem rational and educated people finding the likelihood of an event greater than that of a larger one that encompasses it. I am glad to be a trader taking advantage of people’s biases but I am scared of living in such a society.</p>
<p class="atx"><a id="c11.6.5"/><em>An Absurd World</em> </p>
<p class="tx1">Kafka’s prophetic book, <em>The Trial,</em> about the plight of a man, Joseph K., who is arrested for a mysterious and unexplained reason, hit a spot as it was written before we heard of the methods of the “scientific” totalitarian regimes. It projected a scary future of mankind wrapped in absurd self-feeding bureaucracies, with spontaneously emerging rules subjected to the internal logic of the bureaucracy. It spawned an entire “literature of the absurd”; the world may be too incongruous for us. I am terrified of certain lawyers. After listening to statements during the O. J. trial (and their effect) I was scared, truly scared, of the possible outcome—my being arrested for some reason that made no sense probabilistically, and having to fight some glib lawyer in front of a randomness illiterate jury.</p>
<p class="tx">We said that mere judgment would probably suffice in a primitive society. It is easy for a society to live without mathematics—or traders to trade without quantitative methods—when the space of possible outcomes is one-dimensional. One-dimensional means that we are looking at one sole variable, not a collection of separate events. The price of one security is one-dimensional, whereas the collection of the prices of several securities is multi-dimensional and requires mathematical modeling—we cannot easily see the collection of possible outcomes of the portfolio with a naked eye, and cannot even represent it on a graph as our physical world has been limited to visual representation in three dimensions only. We will argue later why we run the risk of having bad models (admittedly, we have) or making the error of condoning ignorance—swinging between the Carybde of the lawyer who knows no math to the Scylla of the mathematician who misuses his math because he does not have the judgment to select the right model. In other words, we will have to swing between the mistake of listening to the glib nonsense of a lawyer who refuses science and that of applying the flawed theories of some economist who takes his science too seriously. The beauty of science is that it makes an allowance for both error types. Luckily, there is a middle road—but sadly, it is rarely traveled.</p>
<br/>
<p class="epi"><a id="c11.6.6"/><em>Examples of Biases in Understanding Probability</em> </p>
<p class="tx1">I found in the behavioral literature at least forty damning examples of such acute biases, systematic departures from rational behavior widespread across professions and fields. Below is the account of a well-known test, and an embarrassing one for the medical profession. The following famous quiz was given to medical doctors (which I borrowed from the excellent Deborah Bennett’s <em>Randomness</em>).</p>
<br/>
<div class="blockquote"><div class="div"><p class="atx1">A test of a disease presents a rate of 5% false positives. The disease strikes 1/1,000 of the population. People are tested at random, regardless of whether they are suspected of having the disease. A patient’s test is positive. What is the probability of the patient being stricken with the disease?</p></div></div>
<br/>
<p class="tx1">Most doctors answered 95%, simply taking into account the fact that the test has a 95% accuracy rate. The answer is the conditional probability that the patient is sick and the test shows it—close to 2%. Less than one in five professionals got it right.</p>
<p class="tx">I will simplify the answer (using the frequency approach). Assume no false negatives. Consider that out of 1,000 patients who are administered the test, one will be expected to be afflicted with the disease. Out of a population of the remaining 999 healthy patients, the test will identify about 50 with the disease (it is 95% accurate).The correct answer should be that the probability of being afflicted with the disease for someone selected at random who presented a positive test is the following ratio:</p>
<p class="atx">Number of afflicted persons<br/>
________________________<br/>
Number of true and false positives</p>
<p class="tx1">here 1 in 51.</p>
<p class="tx">Think of the number of times you will be given a medication that carries damaging side effects for a given disease you were told you had, when you may only have a 2% probability of being afflicted with it!</p>
<p class="atx"><a id="c11.6.7"/><em>We Are Option Blind</em> </p>
<p class="tx1">As an option trader, I have noticed that people tend to undervalue options as they are usually unable to correctly mentally evaluate instruments that deliver an <em>uncertain</em> payoff, even when they are fully conscious of the mathematics. Even regulators reinforce such ignorance by explaining to people that options are a <em>decaying</em> or <em>wasting</em> asset. Options that are out of the money are deemed to <em>decay,</em> by losing their premium between two dates.</p>
<p class="tx">I will clarify next with a simplified (but sufficient) explanation of what an option means. Say a stock trades at $100 and that someone gives me the right (but not the obligation) to buy it at $110 one month ahead of today. This is dubbed a <em>call</em> option. It makes sense for me to <em>exercise</em> it, by asking the seller of the option to deliver me the stock at $110, only if it trades at a higher price than $110 in one month’s time. If the stock goes to $120, my option will be worth $10, for I will be able to buy the stock at $110 from the option writer and sell it to the market at $120, pocketing the difference. But this does not have a very high probability. It is called <em>out-of-the-money,</em> for I have no gain from exercising it right away.</p>
<p class="tx">Consider that I buy the option for $1. What do I expect the value of the option to be one month from now? Most people think 0. That is not true. The option has a high probability, say 90%, of being worth 0 at expiration, but perhaps 10% probability to be worth an average of $10. Thus, selling the option to me for $1 does not provide the seller with free money. If the seller had instead bought the stock himself at $100 and waited the month, he could have sold it for $120. Making $1 now was hardly, therefore, free money. Likewise, buying it is not a wasting asset. Even professionals can be fooled. How? They confuse the expected value and the most likely scenario (here the expected value is $1 and the most likely scenario is for the option to be worth 0). They mentally overweigh the state that is the most likely, namely, that the market does not move at all. The option is simply the weighted average of the possible states the asset can take.</p>
<p class="tx">There is another type of satisfaction provided by the option seller. It is the steady return and the steady feeling of reward—what psychologists call <em>flow.</em> It is very pleasant to go to work in the morning with the expectation of being up some small money. It requires some strength of character to accept the expectation of bleeding a little, losing pennies on a steady basis even if the strategy is bound to be profitable over longer periods. I noticed that very few option traders can maintain what I call a “long volatility” position, namely a position that will most likely lose a small quantity of money at expiration, but is expected to make money in the long run because of occasional spurts. I discovered very few people who accepted losing $1 for most expirations and making $10 once in a while, even if the game were fair (i.e., they made the $10 more than 9.1% of the time).</p>
<p class="tx">I divide the community of option traders into two categories: <em>premium sellers</em> and <em>premium buyers.</em> Premium sellers (also called option sellers) sell options, and generally make steady money, like John in Chapters <a href="Tale_9781588367679_epub_c01_r1.htm">1</a> and <a href="Tale_9781588367679_epub_c05_r1.htm">5</a>. Premium buyers do the reverse. Option sellers, it is said, eat like chickens and go to the bathroom like elephants. Alas, most option traders I encountered in my career are <em>premium sellers—</em>when they blow up it is generally other people’s money.</p>
<p class="tx">How could professionals seemingly aware of the (simple) mathematics be put in such a position? As previously discussed, our actions are not quite guided by the parts of our brain that dictate rationality. We think with our emotions and there is no way around it. For the same reason, people who are otherwise rational engage in smoking or in fights that get them no immediate benefits; likewise people sell options even when they know that it is not a good thing to do. But things can get worse. There is a category of people, generally finance academics, who, instead of fitting their actions to their brains, fit their brains to their actions. These people go back and unwittingly cheat with the statistics to justify their actions. In my business, they fool themselves with statistical arguments to justify their option selling.</p>
<p class="tx">What is less unpleasant: to lose 100 times $1 or lose once $100? Clearly the second: Our sensitivity to losses decreases. So a trading policy that makes $1 a day for a long time then loses them all is actually pleasant from a hedonic standpoint, although it does not make sense economically. So there is an incentive to invent a story about the likelihood of the events and carry on such strategy.</p>
<p class="tx">In addition, there is the risk ignorance factor. Scientists have subjected people to tests—what I mentioned in the prologue as risk taking out of underestimating the risks rather than courage. The subjects were asked to predict a range for security prices in the future, an upper bound and a lower bound, in such a way that they would be comfortable with 98% of the security ending inside such range. Of course violations to such bound were very large, up to 30%.</p>
<p class="tx">Such violations arise from a far more severe problem: People overvalue their knowledge and underestimate the probability of their being wrong.</p>
<p class="tx">One example to illustrate further option blindness. What has more value? (a) a contract that pays you $1 million if the stock market goes down 10% on any given day in the next year; (b) a contract that pays you $1 million if the stock market goes down 10% on any given day in the next year due to a terrorist act. I expect most people to select (b).</p>
<p class="imp"><a id="c11.7"/><small>PROBABILITIES AND THE MEDIA (MORE JOURNALISTS)</small></p>
<p class="tx1">A journalist is trained in methods to express himself rather than to plumb the depth of things—the selection process favors the most communicative, not necessarily the most knowledgeable. My medical doctor friends claim that many medical journalists do not understand anything about medicine and biology, often making mistakes of a very basic nature. I cannot confirm such statements, being myself a mere amateur (though at times a voracious reader) in medical research, but I have noticed that they almost always misunderstand the probabilities used in medical research announcements. The most common one concerns the interpretation of evidence. They most commonly get mixed up between <em>absence of evidence</em> and <em>evidence of absence,</em> a similar problem to the one we saw in <a href="Tale_9781588367679_epub_c09_r1.htm">Chapter 9</a>. How? Say I test some chemotherapy, for instance Fluorouracil, for upper respiratory tract cancer, and find that it is better than a placebo, but only marginally so; that (in addition to other modalities) it improves survival from 21 per 100 to 24 per 100. Given my sample size, I may not be confident that the additional 3% survival points come from the medicine; it could be merely attributable to randomness. I would write a paper outlining my results and saying that there is no evidence of improved survival (as yet) from such medicine, and that further research would be needed. A medical journalist would pick it up and claim that one Professor N. N. Taleb found evidence that Fluorouracil <em>does not help,</em> which is entirely opposite to my intentions. Some naive doctor in Smalltown, even more uncomfortable with probabilities than the most untrained journalist, would pick it up and build a mental block against the medication, even when some researcher finally finds fresh evidence that such medicine confers a clear survival advantage.</p>
<p class="atx"><a id="c11.7.1"/><em>CNBC at Lunchtime</em> </p>
<p class="tx1">The advent of the financial television channel CNBC presented plenty of benefits to the financial community but it also allowed a collection of extrovert practitioners long on theories to voice them in a few minutes of television time. One often sees respectable people making ludicrous (but smart-sounding) statements about properties of the stock market. Among these are statements that blatantly violate the laws of probability. One summer during which I was assiduous at the health club, I often heard statements such as “the real market is only 10% off the highs while the average stock is close to 40% off its highs,” which is intended to be indicative of deep troubles or anomalies—some harbinger of bear markets.</p>
<p class="tx">There is no incompatibility between the fact that the average stock is down 40% from the highs while the average of all stocks (that is, the market) is down 10% from its own highs. One must consider that the stocks did not all reach their highs <em>at the same time.</em> Given that stocks are not 100% correlated, stock A might reach its maximum in January, stock B might reach its maximum in April, but the average of the two stocks A and B might reach its maximum at some time in February. Furthermore, in the event of negatively correlated stocks, if stock A is at its maximum when stock B is at its minimum, then they could both be down 40% from their maximum when the stock market is at its highs! By a law of probability called distribution of the maximum of random variables, the maximum of an average is necessarily less volatile than the average maximum.</p>
<p class="atx"><a id="c11.7.2"/><em>You Should Be Dead by Now</em> </p>
<p class="tx1">This brings to mind another common violation of probability by prime-time TV financial experts, who may be selected for their looks, their charisma, and their presentation skills, but certainly not for their incisive minds. For instance, a fallacy that I saw commonly made by a prominent TV financial guru goes as follows: “The average American is expected to live seventy-three years. Therefore if you are sixty-eight you can expect to live five more years, and should plan accordingly.” She went into precise prescriptions of how the person should invest for a five-more-years horizon. Now what if you are eighty? Is your life expectancy <em>minus</em> seven years? What these journalists confuse is the unconditional and conditional life expectancy. At birth, your unconditional life expectancy may be seventy-three years. But as you advance in age and do not die, your life expectancy increases along with your life. Why? Because other people, by dying, have taken your spot in the statistics, for expectation means average. So if you are seventy-three and are in good health, you may still have, say, nine years <em>in expectation.</em> But the expectation would change, and at eighty-two, you will have another five years, provided of course you are still alive. Even someone one hundred years old still has a positive conditional life expectation. Such a statement, when one thinks about it, is not too different from the one that says: Our operation has a mortality rate of 1%. So far we have operated on ninety-nine patients with great success; you are our one hundreth, hence you have a 100% probability of dying on the table.</p>
<p class="tx">TV financial planners may confuse a few people. This is quite harmless. What is far more worrying is the supply of information by nonprofessionals to professionals; it is to the journalists that we turn next.</p>
<p class="atx"><a id="c11.7.3"/><em>The Bloomberg Explanations</em> </p>
<p class="tx1">I have, on my desk, a machine eponymously called a <em>Bloomberg</em> (after the legendary founder Michael Bloomberg). It acts as a safe e-mail service, a news service, a historical-data retrieving tool, a charting system, an invaluable analytical aid, and, not least, a screen where I can see the price of securities and currencies. I have gotten so addicted to it that I cannot operate without it, as I would otherwise feel cut off from the rest of the world. I use it to get in contact with my friends, confirm appointments, and solve some of those entertaining quarrels that put some sharpness into life. Somehow, traders who do not have a Bloomberg address do not exist for us (they have to have recourse to the more plebeian Internet). But there is one aspect of Bloomberg I would dispense with: the journalist’s commentary. Why? Because they engage in explaining things and perpetuate the right-column, left-column confusion in a serious manner. Bloomberg is not the sole perpetrator; it is just that I have not been exposed to newspapers’ business sections over the past decade, preferring to read real prose instead.</p>
<p class="tx">As I am writing these lines I see the following headlines on my Bloomberg:</p>
<br/>
<div class="blockquote"><div class="div"><p class="tx1">→<em>Dow is up 1.03 on lower interest rates.</em> </p>
<p class="tx1">→<em>Dollar down 0.12 yen on higher Japanese surplus.</em> </p></div></div>
<br/>
<p class="tx1">and so on for an entire page. If I translate it well, the journalist claims to provide an explanation for something that amounts to <em>perfect noise.</em> A move of 1.03 with the Dow at 11,000 constitutes less than a 0.01% move. Such a move does not warrant an explanation. There is nothing there that an honest person can try to explain; there are no reasons to adduce. But like apprentice professors of comparative literature, journalists being paid to provide explanations will gladly and readily provide them. The only solution is for Michael Bloomberg to stop paying his journalists for providing commentary.</p>
<p class="tx"><em>Significance:</em> How did I decide that it was perfect noise? Take a simple analogy. If you engage in a mountain bicycle race with a friend across Siberia and, a month later, beat him by one single second, you clearly cannot quite boast that you are faster than him. You might have been helped by something, or it can be just plain randomness, nothing else. That second is not in itself significant enough for someone to draw conclusions. I would not write in my pre-bedtime diary: <em>Cyclist A is better than cyclist B because he is fed with spinach whereas cyclist B has a diet rich in tofu. The reason I am making this inference is because he beat him by 1.3 seconds in a 3,000 mile race.</em> Should the difference be one week, then I could start analyzing whether tofu is the reason, or if there are other factors.</p>
<p class="tx"><em>Causality:</em> There is another problem; even assuming statistical significance, one has to accept a cause and effect, meaning that the event in the market can be linked to the cause proffered. <em>Post hoc ergo propter hoc</em> (it is the consequence because it came after). Say hospital A delivered 52% boys and hospital B delivered the same year only 48%; would you try to give the explanation that you had a boy because it was delivered in hospital A?</p>
<p class="tx">Causality can be very complex. It is very difficult to isolate a single cause when there are plenty around. This is called multivariate analysis. For instance, if the stock market can react to U.S. domestic interest rates, the dollar against the yen, the dollar against the European currencies, the European stock markets, the United States balance of payments, United States inflation, and another dozen prime factors, then the journalists need to look at all of these factors, look at their historical effect both in isolation and jointly, look at the stability of such influence, then, after consulting the test statistic, isolate the factor if it is possible to do so. Finally, a proper confidence level needs to be given to the factor itself; if it is less than 90% the story would be dead. I can understand why Hume was extremely obsessed with causality and could not accept such inference anywhere.</p>
<p class="tx">I have a trick to know if something <em>real</em> in the world is taking place. I have set up my Bloomberg monitor to display the price and percentage change of all relevant prices in the world: currencies, stocks, interest rates, and commodities. By dint of looking at the same setup for years, as I keep the currencies in the upper left corner and the various stock markets on the right, I managed to build an instinctive way of knowing if something serious is going on. The trick is to look only at the large percentage changes. Unless something moves by more than its usual daily percentage change, the event is deemed to be noise. Percentage moves are the size of the headlines. In addition, the interpretation is not linear; a 2% move is not twice as significant an event as 1%, it is rather like four to ten times. A 7% move can be several billion times more relevant than a 1% move! The headline of the Dow moving by 1.3 points on my screen today has less than one billionth of the significance of the serious 7% drop of October 1997. People might ask me: Why do I want everybody to learn some statistics? The answer is that too many people read explanations. We cannot instinctively understand the nonlinear aspect of probability.</p>
<p class="atx"><a id="c11.7.4"/><em>Filtering Methods</em> </p>
<p class="tx1">Engineers use methods to clean up the noise from the signal in the data. Did it ever occur to you while talking to your cousin in Australia or the South Pole that the static on the telephone line could be distinguished from the voice of your correspondent? The method is to consider that when a change in amplitude is small, it is more likely to result from noise—with its likelihood of being a signal increasing exponentially as its magnitude increases. The method is called a smoothing kernel, which has been applied in Figures 11.1 and 11.2. But our auditory system is incapable of performing such a function by itself. Likewise our brain cannot see the difference between a significant price change and mere noise, particularly when it is pounded with unsmoothed journalistic noise.</p>
<p class="atx"><a id="c11.7.5"/><em>We Do Not Understand Confidence Levels</em> </p>
<p class="atx"><img alt="image" src="images/Tale_9781588367679_epub_008_r1.jpg"/></p>
<p class="cap">Figure 11.1 Unfiltered Data Containing Signal and Noise</p>
<p class="atx"><img alt="image" src="images/Tale_9781588367679_epub_009_r1.jpg"/></p>
<p class="cap">Figure 11.2 Same Data with Its Noise Removed</p>
<p class="tx1">Professionals forget the following reality. It is not the estimate or the forecast that matters so much as the degree of confidence with the opinion. Consider that you are going on a trip one fall morning and need to formulate an idea about the weather conditions prior to packing your luggage. If you expect the temperature to be 60 degrees, plus or minus 10 degrees (say in Arizona), then you would take no snow clothes and no portable electric fan. Now, what if you were going to Chicago, where you are told that the weather, while being 60 degrees, will nevertheless vary by about 30 degrees? You would have to pack winter and summer clothes. Here the expectation of the temperature carries little importance concerning the choice of clothing; it is the variance that matters. Your decision to pack is markedly different now that you are told that the variability would be around 30 degrees. Now let us push the point further; what if you were going to a planet where the expectation is also going to be around 60 degrees, but plus or minus 500 degrees? What would you pack?</p>
<p class="tx">We can see that my activity in the market (and other random variables) depends far less on where I think the market or the random variable is going so much as it does on the degree of error I allow around such a confidence level.</p>
<p class="atx"><a id="c11.7.6"/><em>An Admission</em> </p>
<p class="tx1">We close this chapter with the following information: I consider myself as prone to foolishness as anyone I know, in spite of my profession and the time spent building my expertise on the subject. But here is the exception; I know that I am very, very weak on that score. My humanity will try to foil me; I have to stay on my guard. I was born to be fooled by randomness. That will be explored in Part III.</p></div>
</body></html>