<?xml version="1.0" encoding="UTF-8" standalone="no"?><html xmlns="http://www.w3.org/1999/xhtml"><head>
<title>Fooled By Randomness</title>
<link href="Tale_9781588367679_epub_css_r1.css" rel="stylesheet" type="text/css"/>
<meta name="Adept.resource" value="urn:uuid:5357f980-a6ae-4120-b5a6-e0821e7ce051"/></head>
<body><div id="nts">
<p class="ct">A TRIP TO THE LIBRARY</p>
<p class="fmh1"><em>Notes and Reading Recommendations</em> </p>
<p class="imp"><a id="nts.1"/>NOTES</p>
<p class="atx1">I confess that, as a practitioner of randomness, I focused primarily on the defects of my <em>own</em> thinking (and that of a few people I’ve observed or tracked through time). I also intended the book to be playful, which is not very compatible with referencing every idea to some scientific paper to give it a degree of respectability. I take the liberty in this section to finesse a few points and to provide select references (of the “further reading” variety)—but references linked to matters that I directly experienced. I repeat that this is a personal essay, not a treatise.</p>
<p class="atx1">                           On completion of this compilation I discovered the predominance of matters relating to human nature (mostly empirical psychology) over things mathematical. Sign of the times: I am convinced that the next edition, hopefully two years from now, will have plenty of references and notes in neurobiology and neuroeconomics.</p>
<p class="imp"><small>PREFACE</small></p>
<p class="atx1"><b>Hindsight bias:</b> a.k.a Monday morning quarterback. See Fischhoff (1982).</p>
<br/>
<p class="atx1"><b>Clinical knowledge:</b> The problem of clinicians not knowing what they do not know, and not quite figuring it out. See Meehl (1954) for the seminal introduction. “It is clear that the dogmatic, complacent assertion sometimes heard from clinicians that ‘naturally’ clinical prediction, being based on ‘real understanding’ is superior, is simply not justified by the facts to date.” In his testing, in all but one case, predictions made by actuarial means were equal to or better than clinical methods. Even worse: In a later paper, he changed his mind about that one exception. Since Meehl’s work there has been a long tradition of examination of expert opinions, confirming the same results. This problem applies to about every profession—particularly journalists and economists. We will discuss in further notes the associated problem of self-knowledge.</p>
<br/>
<p class="atx1"><b>Montaigne vs Descartes:</b> I thank the artificial intelligence researcher and omnivorous reader Peter McBurney for bringing to my attention the discussion in Toulmin (1990). On that I have to make the sad remark that Descartes was originally a skeptic (as attested by his demon thought experiment) but the so-called Cartesian mind corresponds to someone with an appetite for certainties. Descartes’ idea in its original form is that there are very few certainties outside of narrowly defined deductive statements, not that everything we think about needs to be deductive.</p>
<br/>
<p class="atx1"><b>Affirming the consequent:</b> The logical fallacy is generally presented as follows.</p>
<br/>
<p class="atx1">If p then q</p>
<br/>
<p class="atx1">q</p>
<br/>
<p class="atx1">Therefore, p</p>
<br/>
<p class="atx1">(All people in the Smith family are tall; he is tall therefore he belongs to the Smith family).</p>
<p class="atx1">                           The track record of the general population in correctly making such inference is exceedingly poor. Although it is not customary to quote textbooks, I refer the reader to the excellent Eysenck and Keane (2000) for a list of the research papers on the different difficulties—up to 70% of the population can make such a mistake!</p>
<br/>
<p class="atx1"><b>The millionaire mind:</b> Stanley (2000). He also figured out (correctly) that the rich were “risk takers” and inferred (incorrectly) that risk taking made one rich. Had he examined the population of failed entrepreneurs he would have also inferred (correctly) that the failed entrepreneurs too were “risk takers.”</p>
<br/>
<p class="atx1"><b>Journalists are “practical”:</b> I heard at least four times the word <em>practical</em> on the part of journalists trying to justify their simplification. The television show that wanted me to present three stock recommendations wanted something “practical,” not theories.</p>
<br/>
<p class="imp"><small>PROLOGUE</small></p>
<p class="atx1"><b>Mathematics conflicts with probability:</b> One is about certainties, the other about the exact opposite. This explains the disrespect held by pure mathematicians for the subject of probability for a long time—and the difficulty in integrating the two. It is not until recently that it was termed “the logic of science”—the title of the posthumous Jaynes (2003). Interestingly, this book is also perhaps the most complete account of the mathematics of the subject—he manages to use probability as an expansion of conventional logic.</p>
<p class="tx">The prominent mathematician David Mumford, a Fields medalist, repents for his former scorn for probability. He writes in <em>The Dawning of the Age of Stochasticity</em> (Mumford, 1999): “For over two millennia, Aristotle’s logic has ruled over the thinking of Western intellectuals. All precise theories, all scientific models, even models of the process of thinking itself, have in principle conformed to the straight-jacket of logic. But from its shady beginnings devising gambling strategies and counting corpses in medieval London, probability theory and statistical inference now emerge as better foundations for scientific models, especially those of the process of thinking and as essential ingredients of theoretical mathematics, even the foundations of mathematics itself. We propose that this sea change in our perspective will affect virtually all of mathematics in the next century.”</p>
<br/>
<p class="atx1"><b>Courage or foolishness:</b> For an examination of that notion of “courage” and “guts,” see Kahneman and Lovallo (1993). See also a discussion in Hilton (2003). I drew the idea from Daniel Kahneman’s presentation in Rome in April 2003 (Kahneman, 2003).</p>
<br/>
<p class="atx1"><b>Cognitive errors in forecasting:</b> Tversky and Kahneman (1971), Tversky and Kahneman (1982), and Lichtenstein, Fischhoff and Phillips (1977).</p>
<br/>
<p class="atx1"><b>Utopian/tragic:</b> The essayist and prominent (scientific) intellectual Steven Pinker popularized the distinction (originally attributable to the political scholar Thomas Sowell). See Sowell (1987), Pinker (2002). Actually, the distinction is not so clear. Some people actually believe, for instance, that Milton Friedman is a utopist in the sense that all ills come from governments and that getting rid of government would be a great panacea.</p>
<br/>
<p class="atx1"><b>Fallibility and infallibilism:</b> Peirce (in a prospectus for a never written book), writes, “Nothing can be more completely contrary to a philosophy, the fruit of a scientific life, than infallibilism, whether arrayed in the old ecclesiastical trappings, or under its recent ‘scientific’ disguise.” (Brent, 1993). For a brief and very readable acquaintance to the works of Peirce, Menand (2001). It draws on his sole biography, Brent (1993).</p>
<br/>
<p class="imp"><small>CHAPTER 1</small></p>
<p class="atx1"><b>Relative compared to absolute position:</b> See Kahneman, Knetsch and Thaler (1986). Robert Frank is an interesting researcher who spent part of his career thinking about the problem of status, rank, and relative income: See Frank (1985), and the very readable Frank (1999). The latter includes discussions on the interesting proposer/responder problem where people forego windfall profits in order to deprive others of a larger share. One person proposes to the other a share of, say, $100. She can accept or refuse. If she refuses, both get nothing.</p>
<p class="atx1">Even more vicious results have been shown by researchers who studied how much people would <em>pay</em> to lower other people’s income: See Zizzo and Oswald (2001). On that also, see Burnham (2003) (he ran an experiment measuring the testosterone levels in economic exchange).</p>
<br/>
<p class="atx1"><b>Serotonin and pecking order:</b> Frank (1999) includes a discussion.</p>
<br/>
<p class="atx1"><b>On the social role of the psychopath:</b> See Horrobin (2002). While it may have some extreme views on the point, the book reviews discussions of the theories around the success realized by the psychopaths. Also, see Carter (1999) for a presentation of the advantage some people have in being separated from the feeling of empathy and compassion.</p>
<br/>
<p class="atx1"><b>Social emotions:</b> Damasio (2003): “One of the many reasons why people become leaders and others followers, why so many command respect, has little to do with knowledge or skills and a lot to do with how some physical traits and the manner of a given individual promote certain emotional responses in others.”</p>
<br/>
<p class="atx1"><b>Literature on emotions:</b> For a review of the current scientific ideas, see the excellent compact Evans (2002). Evans belongs to the new breed of the philosopher/essayist contemplating large themes with a scientific mind. Elster (1998) goes into the broad social implications of emotions. The bestselling Goleman (1995) offers a surprisingly complete account (the fact that it is a bestseller is surprising: We are aware of our irrationality but it does not seem to help).</p>
<br/>
<p class="imp"><small>CHAPTER 2</small></p>
<p class="atx1"><b>Possible worlds:</b> Kripke (1980).</p>
<br/>
<p class="atx1"><b>Many worlds:</b> See the excellently written Deutsch (1997). I also suggest a visit to the author’s rich website. The earlier primary work can be found in DeWitt and Graham (1973), which contains Hugh Everett’s original paper.</p>
<br/>
<p class="atx1"><b>Economics of uncertainty and possible states of nature:</b> See Debreu (1959). For a presentation of lattice state-space methods in mathematical finance, see Ingersoll (1987) (well structured though dry and very, very boring, like the personality of its author), and the more jargon-laden Huang and Litzenberger (1988). For an economics-oriented presentation, see Hirshleifer and Riley (1992).</p>
<br/>
<p class="atx1"><b>For the works of Shiller:</b> See Shiller (2000). The more technical work is in the (originally) controversial Shiller (1981). See also Shiller (1990). For a compilation: Shiller (1989). See also Kurz (1997) for a discussion of endogenous uncertainty.</p>
<br/>
<p class="atx1"><b>Risk and emotions:</b> Given the growing recent interest in the emotional role in behavior, there has been a growing literature on the role of emotions in both risk bearing and risk avoidance: The “risk as feeling” theory: See Loewenstein, Weber, Hsee and Welch (2001), and Slovic, Finucane, Peters and MacGregor (2003a). For a survey, see Slovic, Finucane, Peters and MacGregor (2003b). See also Slovic (1987).</p>
<br/>
<p class="atx1"><b>For a discussion of the affect heuristic:</b> See Finucane, Alhakami, Slovic and Johnson (2000).</p>
<br/>
<p class="atx1"><b>Emotions and cognition:</b> For the effect of emotions on cognition, see LeDoux (2002).</p>
<br/>
<p class="atx1"><b>Availability heuristic (how easily things come to mind):</b> Tversky and Kahneman (1973).</p>
<br/>
<p class="atx1"><b>Real incidence of catastrophes:</b> For an insightful discussion, see Albouy (2002).</p>
<br/>
<p class="atx1"><b>On sayings and proverbs:</b> Psychologists have long examined the gullibility of people in social settings facing well-sounding proverbs. For instance, experiments since the 1960s have been made where people are asked whether they believed that a proverb is right, while another cohort is presented the opposite meaning. For a presentation of the hilarious results, see Myers (2002).</p>
<br/>
<p class="atx1"><b>Epiphenomena:</b> See the beautiful Wegner (2002).</p>
<br/>
<p class="imp"><small>CHAPTER 3</small></p>
<br/>
<p class="atx1"><b>Keynes:</b> Keynes’ <em>Treatise on Probability</em> (Keynes, 1989, 1920) remains in many people’s opinion the most important single work on the subject—particularly considering Keynes’ youth at the time of composition (it was published years after he finished it). In it he develops the critical notion of subjective probability.</p>
<br/>
<p class="atx1"><b><em>Les gommes:</em></b> Robbe-Grillet (1985).</p>
<br/>
<p class="atx1"><b>Pseudoscientific historicism:</b> For an example, I suggest Fukuyama (1992).</p>
<br/>
<p class="atx1"><b>Fears built into our genes:</b> This is not strictly true—genetic traits need to be culturally activated. We are wired for some fears, such as fears of snakes, but monkeys who have never seen a snake do not have it. They need the sight of the fear in the facial features of another monkey to start getting scared (LeDoux, 1998).</p>
<br/>
<p class="atx1"><b>Amnesia and risk avoidance:</b> Damasio (2000) presents the case of David the amnesic patient who knew to avoid those who abused him. See also Lewis, Amini and Lannon (2000). Their book presents a pedagogic discussion of “camouflaged learning,” in the form of implicit memory, as opposed to explicit memory (neocortical). The book portrays memory as a correlation in neuron connectivity rather than some CD-style recording—which explains the revisions of memory by people after events.</p>
<br/>
<p class="atx1"><b>Why don’t we learn from our past history?:</b> Two strains of literature. (1) The recent “stranger to ourselves” line of research in psychology (Wilson 2002). (2) The literature on “immune neglect,” Wilson, Meyers and Gilbert (2001) and Wilson, Gilbert and Centerbar (2003). Literally, people don’t learn from their past reactions to good and bad things.</p>
<br/>
<p class="atx1"><b>Literature on bubbles:</b> There is a long tradition, see Kindleberger (2001), MacKay (2002), Galbraith (1991), Chancellor (1999), and of course Shiller (2000). Shiller with a little work may be convinced to do a second edition.</p>
<br/>
<p class="atx1"><b>Long-term capital management:</b> See Lowenstein (2000).</p>
<br/>
<p class="atx1"><b>Stress and randomness:</b> Sapolsky (1998) is a popular, sometimes hilarious presentation. The author specializes among other things on the effect of glucocorticoids released at times of stress on the atrophy of the hycocampus, hampering the formation of new memory and brain plasticity. More technical, Sapolsky (2003).</p>
<br/>
<p class="atx1"><b>Brain asymmetries with gains/losses:</b> See Gehring and Willoughby (2002). See the works of Davidson on the anterior brain asymmetry (a clear summary and popular presentation in Goleman 2003). See also Shizgal (1999).</p>
<br/>
<p class="atx1"><b>The dentist and prospect theory:</b> Kahneman and Tversky (1979). In this seminal discussion they present agents as interested in differences and resetting their pain/pleasure level at zero as “anchor.” The gist of it is that “wealth” does not matter, almost only differences in wealth, since the resetting cancels the effect of the accumulation. Think of John hitting wealth of $1 million from below or above and the impact on his well-being. The difference between utility of wealth and utility of changes in wealth is not trivial: It leads to dependence on the observation period. In fact the notion, taken to its limit, leads to the complete revision of economic theory: Neoclassical economics will no longer be useful beyond mathematical exercises. There have been vigorous such discussions in the hedonistic literature as well: See Kahneman, Diener and Schwarz (1999).</p>
<br/>
<p class="imp"><small>CHAPTER 4</small></p>
<br/>
<p class="atx1"><b>Public and scientific intellectual:</b> Brockman (1995) offers presentations by the “who’s who” in the new scientific intellectual tradition. See also his website, <a href="http://www.edge.org">www.edge.org</a>. For a physicist’s position on the culture wars, Weinberg (2001). For a presentation of a public intellectual, see Posner (2002). Note that Florida Atlantic University offers a Ph.D. to become a public intellectual—literary, since scientists need no such artifice.</p>
<br/>
<p class="atx1"><b>The hoax:</b> Sokal (1996).</p>
<br/>
<p class="atx1"><b><em>The Selfish Gene:</em> </b>Dawkins (1989, 1976). Hegel: In Popper (1994).</p>
<br/>
<p class="atx1"><b>Exquisite cadavers:</b> Nadeau (1970).</p>
<br/>
<p class="atx1"><b>The generator:</b> <a href="http://www.monash.edu.au">www.monash.edu.au</a>.</p>
<br/>
<p class="atx1"><b>Language and probability:</b> There is a very large connection between language and probability; it has been studied by thinkers and scientists via the sister methods of entropy and information theory—one can reduce the dimensionality of a message by eliminating redundancy, for instance; what is left is measured as information content (think of zipping a file) and is linked to the notion of “entropy,” which is the degree of disorder, the unpredictable that is left. Entropy is a very invasive notion as it relates to aesthetics and thermodynamics. See Campbell (1982) for a literary presentation, and Cover and Thomas (1991) for a scientific one, particularly the discussion on the “entropy of English.” For a classic discussion of entropy and art, Arnheim (1971), though the connection between entropy and probability was not yet clear at the time. See Georgescu-Roegen (1971) for a (perhaps) pioneering discussion of entropy in economics.</p>
<br/>
<p class="imp"><small>CHAPTER 5</small></p>
<br/>
<p class="atx1"><b>The firehouse effect and the convergence of opinions:</b> There are plenty of discussions in the psychology literature of such convergence of opinions, particularly in the area of mate selection or what Keynes calls “the beauty contest,” as people tend to choose what other people choose, causing positive-feedback loops.</p>
<p class="tx">An interesting manifestation is the autokinetic effect. When people gaze at a stationary light in a room they see it moving after a while and can estimate the amount of movement, not knowing that it is an optical illusion. When isolated the subjects give wildly varying speeds of movement; when tested in a group they converge to a common speed of movement: See Plotkin (1998). Sornette (2003) gives an interesting account of the feedback loops that result from herding written in light, but with extremely intuitive mathematics.</p>
<br/>
<p class="atx1"><b>Biology of imitation:</b> See Dugatkin (2001).</p>
<br/>
<p class="atx1"><b>Evolution and small probabilities:</b> Evolution is principally a probabilistic concept. Can it be fooled by randomness? Can the least skilled survive? There is a prevalent strain of Darwinism, called naive Darwinism, that believes that any species or member of a species that dominates at any point has been selected by evolution because they have an advantage over others. This results from a common misunderstanding of local and global optima, mixed with an inability to get rid of the belief in the law of small numbers (overinference from small data sets). Just put two people in a random environment, say a gambling casino, for a weekend. One of them will fare better than the other. To a naive observer the one who fares better will have a survival advantage over the other. If he is taller or has some trait that distinguishes him from the other, such trait will be identified by the naive observer as the explanation of the difference in fitness. Some people do it with traders—make them compete in a formal competition. Consider also the naive evolutionary thinking positing the “optimality” of selection—the founder of sociobiology does not agree with such optimality when it comes to rare events: E. O. Wilson (2002) writes: “The human brain evidently evolved to commit itself emotionally only to a small piece of geography, a limited band of kinsmen, and two or three generations into the future. To look neither far ahead nor far afield is elemental in a Darwinian sense. <em>We are innately inclined to ignore any distant possibility not yet requiring examination. It is, people say, just good common sense.</em> Why do they think in this shortsighted way? “The reason is simple: It is a hardwired part of our Paleolithic heritage. For hundreds of millennia, those who worked for short-term gain within a small circle of relatives and friends lived longer and left more offspring—even when their collective striving caused their chiefdoms and empires to crumble around them. The long view that might have saved their distant descendants required a vision and extended altruism instinctively difficult to marshal.”</p>
<p class="tx">See also Miller (2000): “Evolution has no foresight. It lacks the long-term vision of drug company management. A species can’t raise venture capital to pay its bills while its research team . . . Each species has to stay biologically profitable every generation, or else it goes extinct. Species always have cashflow problems that prohibit speculative investments in their future. More to the point, every gene underlying every potential innovation has to yield higher evolutionary payoffs than competing genes, or it will disappear before the innovation evolves any further. This makes it hard to explain innovations.”</p>
<p class="imp"><small>CHAPTER 6</small></p>
<p class="atx1"><b>Fooled by negative skewness:</b> The first hint of an explanation for the popularity of negatively skewed payoffs comes from the early literature on behavior under uncertainty, with the “small number problem.” Tversky and Kahneman (1971) write: “We submit that people view a sample randomly drawn from a population as highly representative, that is, similar to a population in all essential characteristics.” The consequence is the inductive fallacy: overconfidence in the ability to infer general properties from observed facts, “undue confidence in early trends,” the stability of observed patterns and deriving conclusions with more confidence attached to them than can be warranted by the data. Worst, the agent finds causal explanations or perhaps distributional attributes that confirm his undue generalization. It is easy to see that the “small numbers” get exacerbated with skewness since most of the time the observed mean will be different from the true mean and most of the time the observed variance will be lower than the true one. Now consider that it is a fact that in life, unlike a laboratory or a casino, we do not observe the probability distribution from which random variables are drawn: We only see the realizations of these random processes. It would be nice if we could, but it remains that we do not measure probabilities as we would measure the temperature or the height of a person. This means that when we compute probabilities from past data we are making assumptions about the skewness of the generator of the random series—all data is conditional upon a generator. In short, with skewed packages, the camouflage of the properties comes into play <em>and</em> we tend to believe what we see. Taleb (2004).</p>
<br/>
<p class="atx1"><b>Philosopher sometimes playing scientist:</b> Nozik (1993).</p>
<br/>
<p class="atx1"><b>Hollywood economics:</b> De Vany (2003).</p>
<br/>
<p class="atx1"><b>People are sensitive to sign rather than magnitude:</b> Hsee and Rottenstreich (2004).</p>
<br/>
<p class="atx1"><b>Lucas critique:</b> Lucas (1978).</p>
<p class="imp"><small>CHAPTER 7</small></p>
<p class="atx1"><b>Niederhoffer’s book:</b> Niederhoffer (1997).</p>
<br/>
<p class="atx1"><b>Goodman’s riddle of induction:</b> One can take the issue of induction into a more difficult territory with the following riddle. Say the market went up every day for a month. For many people of inductive taste it could confirm the theory that it is going up every day. But consider: It may confirm the theory that it goes up every day then crashes—what we are witnessing is not an ascending market but one that <em>ascends then crashes.</em> When one observes a blue object it is possible to say that one is observing something blue until time <em>t,</em> beyond which it is green—that such object is not blue but “grue.” Accordingly, by such logic, the fact that the market went up all this time may confirm that it will crash tomorrow! It confirms that we are observing a rising-crashing market. See Goodman (1954).</p>
<br/>
<p class="atx1"><b>Writings by Soros:</b> Soros (1988).</p>
<br/>
<p class="atx1"><b>Hayek:</b> See Hayek (1945) and the prophetic Hayek (1994), first published in 1945.</p>
<br/>
<p class="atx1"><b>Popper’s personality:</b> Magee (1997), and Hacohen (2001). Also an entertaining account in Edmonds and Eidinow (2001).</p>
<p class="imp"><small>CHAPTER 8</small></p>
<p class="atx1">The millionaire next door: Stanley (1996).</p>
<br/>
<p class="atx1"><b>Equity premium puzzle:</b> There is an active academic discussion of the “equity premium” puzzle, taking the “premium” here to be the outperformance of stocks in relation to bonds and looking for possible explanations. Very little consideration was given to the possibility that the premium may have been an optical illusion owing to the survivorship bias—or that the process may include the occurrence of black swans. The discussion seems to have calmed a bit after the declines in the equity markets after the events of 2000–2002.</p>
<p class="imp"><small>CHAPTER 9</small></p>
<p class="atx1"><b>Hot-hand effect:</b> Gilovich, Vallone and Tversky (1985).</p>
<br/>
<p class="atx1"><b>Stock analysts fooled by themselves:</b> For a comparison between analysts and weather forecasters, see Taszka and Zielonka (2002).</p>
<br/>
<p class="atx1"><b>Differences between returns:</b> See Ambarish and Siegel (1996). The dull presenter was actually comparing “Sharpe ratios,” i.e., returns scaled by their standard deviations (both annualized), named after the financial economist William Sharpe, but the concept has been commonly used in statistics and called “coefficient of variation.” (Sharpe introduced the concept in the context of the normative theory of asset pricing to compute the expected portfolio returns given some risk profile, not as a statistical device.) Not counting the survivorship bias, over a given twelve-month period, assuming (very generously) the Gaussian distribution, the “Sharpe ratio” differences for two uncorrelated managers would exceed 1.8 with close to 50% probability. The speaker was discussing “Sharpe ratio” differences of around .15! Even assuming a five-year observation window, something very rare with hedge fund managers, things do not get much better.</p>
<p class="atx1"><b>Value of the seat:</b> Even then, by some attribution bias, traders tend to believe that their income is due to their skills, not the “seat,” or the “franchise” (i.e., the value of the order flow).The seat has a value as the New York Stock Exchange specialist “book” is worth quite large sums: See Hilton (2003). See also Taleb (1997) for a discussion of the time and place advantage.</p>
<br/>
<p class="atx1"><b>Data mining:</b> Sullivan, Timmermann and White (1999).</p>
<br/>
<p class="atx1"><b>Dogs not barking:</b> I thank my correspondent Francesco Corielli from Bocconi for his remark on meta-analysis.</p>
<p class="imp"><small>CHAPTER 10</small></p>
<p class="atx1"><b>Networks:</b> Arthur (1994). See Barabasi (2002), Watts (2003).</p>
<br/>
<p class="atx1"><b>Nonlinear dynamics:</b> For an introduction to nonlinear dynamics in finance, see Brock and De Lima (1995), and Brock, Hsieh and LeBaron (1991). See also the recent, and certainly the most complete, Sornette (2003). Sornette goes beyond just characterizing the process as fat-tailed and saying that the probability distribution is different from the one we learned in Finance 101. He studies the transition points: Say a book’s sales become close to a critical point from which they will really take off. Their dynamics, conditional on past growth, become predictable.</p>
<br/>
<p class="atx1"><b><em>The Tipping Point:</em></b> Gladwell (2000). In the article that preceded the book (Gladwell,1996) he writes:“The reason this seems surprising is that human beings prefer to think in linear terms . . . . I can remember struggling with these same theoretical questions as a child, when I tried to pour ketchup on my dinner. Like all children encountering this problem for the first time, I assumed that the solution was linear: That steadily increasing hits on the base of the bottle would yield steadily increasing amounts of ketchup out the other end. Not so, my father said, and he recited a ditty that, for me, remains the most concise statement of the fundamental nonlinearity of everyday life: ‘Tomato ketchup in a bottle—None will come and then the lot’ll.’ ”</p>
<br/>
<p class="atx1"><b>Pareto:</b> Before we had a generalized use of the bell curve, we took the ideas of Pareto with his distribution more seriously—its mark is the contribution of large deviations to the overall properties. Later elaborations led to the so-called Pareto-Levy or Levy-Stable distributions with (outside of special cases) some quite vicious properties (no known error rate). The reasons economists never liked to use it is that it does not offer tractable properties—economists like to write papers in which they offer the illusion of solutions, particularly in the form of mathematical answers. A Pareto-Levy distribution does not provide them with such luxury. For economic discussions on the ideas of Pareto, see Zajdenweber (2000), Bouvier (1999). For a presentation of the mathematics of Pareto-Levy distributions, see Voit (2001), and Mandelbrot (1997). There is a recent rediscovery of power law dynamics. Intuitively a power law distribution has the following property: If the power exponent were 2, then there would be 4 times more people with an income higher than $1 million than people with $2 million. The effect is that there is a very small probability of having an event of an extremely large deviation. More generally given a deviation <em>x,</em> the incidence of a deviation of a multiple of <em>x</em> will be that multiple to a given power exponent. The higher the exponent the lower the probability of a large deviation.</p>
<br/>
<p class="atx1"><b>Spitznagel’s remark:</b> In Gladwell (2002).</p>
<br/>
<p class="atx1"><b>Don’t take “correlation” and those who use the word seriously:</b> The same “A.” of the lighterthrowing variety taught me a bit about the fallacy of the notion of correlation. “You do not seem to be correlated to anything” is the most common blame I’ve received when carrying my strategy of shooting for rare events. The following example might illustrate it. A nonlinear trading instrument, such as a put, will be positively correlated to the underlying security over many sample paths (say the put expires worthless in a bear market as the market did not drop enough), except of course upon becoming in the money and crossing the strike, in which case the correlation reverses with a vengeance. The reader should do himself a favor by not taking the notion of correlation seriously except in very narrow matters where linearity is justified.</p>
<p class="imp"><small>CHAPTER 11</small></p>
<br/>
<p class="atx1"><b>Probability “blindness”:</b> I borrow the expression from Piattelli-Palmarini (1994).</p>
<br/>
<p class="atx1"><b>Discussion of “rationality”:</b> The concept is not so easy to handle. As the concept has been investigated in plenty of fields, it has been developed the most by economists as a normative theory of choice. Why did the economists develop such an interest in it? The basis of economic analysis is a concept of human nature and rationality embodied in the notion of <em>homo economicus.</em> The characteristics and behavior of such <em>homo economicus</em> are built into the postulates of consumer choice and include nonsatiation (more is <em>always</em> preferred to less) and transitivity (global consistency in choice). For instance, Arrow (1987) writes, “It is note-worthy that the everyday usage of the term ‘rationality’ does not correspond to the economist’s definition as transitivity and completeness, that is maximization of something. The common understanding is instead the complete exploitation of information, sound reasoning, and so forth.”</p>
<br/>
<p class="atx1">Perhaps the best way to see it for an economist is the maximization leading to a unique solution.</p>
<br/>
<p class="atx1">Even then, it is not easy. Who is maximizing what? To begin, there is a conflict between collective and individual rationality (“tragedy of the commons” seen by Keynes in his parable of the stadium where one’s optimal strategy is to stand up, but collectively the optimal strategy is for everyone to remain seated). Another problem is seen in Arrow’s voter’s impossibility theorem. Consider also the following voter problem: People vote but the probability adjusted gains from voting can be less than the effort expended in going to the polling place. See Luce and Raiffa (1957) for a discussion of these paradoxes.</p>
<br/>
<p class="atx1">Note that the literature on rational choice under uncertainty is very extensive, cutting across fields, from evolutionary game theory to political science. But as John Harsanyi put it bluntly, <em>It is normative, and meant to be so.</em> This is a heroic statement: Saying that economics has abandoned its scientific pretensions and accepted that it does not describe how people <em>do</em> act but rather how they <em>should</em> act. It means that it has entered the realm of something else: philosophy (though not quite ethics). As such, an individual can accept it fully and should aim to act like the neoclassical man. If he can.</p>
<br/>
<p class="atx1"><b>Ultimate/proximate as a solution to some rationality problems:</b> Evolutionary theorists distinguish between proximate and ultimate cause.</p>
<br/>
<p class="atx1">Proximate cause: I eat <em>because</em> I am hungry.</p>
<p class="atx1">Ultimate cause: If I didn’t have an incentive to eat I would have gracefully exited the gene pool.</p>
<br/>
<p class="tx">Now, if one invokes ultimate causes, plenty of behavior deemed locally irrational (like the voter problem above) can be interpreted as rational. It explains altruism: Why would you take a small risk to help a stranger from drowning? Visibly this impetus to help put us where we are today.</p>
<p class="tx">See Dawkins (1989, 1976) and Pinker (2002) for additional insights on the difference.</p>
<br/>
<p class="atx1"><b>Rationality and scientism:</b> Under the suggestion of my correspondent Peter McBurney I discovered the novel <em>We</em> by Yevgeny Zamyatin, a satire on Leninist Russia written in the 1920s and set in the far distant future, at a time when Taylorist and rationalist ideas had succeeded, apparently, in eliminating all uncertainty and irrationality from life.</p>
<br/>
<p class="atx1"><b>Bounded rationality:</b> Simon (1956), Simon (1957), Simon (1987a), and Simon (1987b).</p>
<br/>
<p class="atx1"><b>Birth of the neurobiology of rationality:</b> Berridge (2003) introduces a neurobiological dimension to rationality using two of Daniel Kahneman’s four utilities (the experienced, remembered, predicted, and decision utilities) and setting irrationality if the decision utility exceeds the predicted one. There is a neural dimension to such irrationality: dopamine activity in the mesolimbic brain.</p>
<br/>
<p class="atx1"><b>Compilation of the heuristics and biases papers in four volumes:</b> Kahneman, Slovic and Tversky (1982), Kahneman and Tversky (2000), Gilovich, Griffin and Kahneman (2002), and Kahneman, Diener and Schwarz (1999).</p>
<br/>
<p class="atx1"><b>Two systems of reasoning:</b> See Sloman (1996), and Sloman (2002). See the summary in Kahneman and Frederick (2002). For the affect heuristic, see Zajonc (1980), and Zajonc (1984).</p>
<br/>
<p class="atx1"><b>Evolutionary psychology/sociobiology:</b> The most readable is Burnham and Phelan (2000). See Kreps and Davies (1993) for the general framework of ecology as optimization. See also Wilson (E. O., 2000), Winston (2002), the cartoons of Evans and Zarate (1999), Pinker (1997), and Burnham (1997).</p>
<br/>
<p class="atx1"><b>Modularity:</b> For the seminal work, see Fodor (1983) in philosophy and cognitive science, Cosmides and Tooby (1992) in evolutionary psychology.</p>
<br/>
<p class="atx1">The Wason selection task (written about in nearly every book on evolutionary psychology) is as follows. Consider the following two tests:</p>
<br/>
<p class="atx1">Problem 1: Suppose that I have a pack of cards, each of which has a letter written on one side and a number written on the other side. Suppose in addition that I claim that the following rule is true: <em>If a card has a vowel on one side, then it has an even number on the other side.</em> Imagine that I now show you four cards from the pack: E 6 K 9. Which card or cards should you turn over in order to decide whether the rule is true or false?</p>
<br/>
<p class="atx1">Problem 2: You are a bartender in a town where the legal age for drinking is twenty-one and feel responsible for the violations of the rules. You are confronted with the following situations and would have to ask the patron to show you either his age or what he is drinking. Which of the four patrons would you have to question?</p>
<br/>
<p class="atx1">1, drinking beer; 2, over twenty-one; 3, drinking Coke; 4, under 21.</p>
<br/>
<p class="atx1">While the two problems are identical (it is clear that you need to check only the first and last of the four cases) the majority of the population gets the first one wrong and the second one right. Evolutionary psychologists believe that the defects in solving the first problem and ease in the second show evidence of a cheater detection module—just consider that we adapted to the enforcement of cooperative tasks and are quick at identifying free riders.</p>
<br/>
<p class="atx1"><b>Criteria of modularity:</b> I borrow from the linguist Elisabeth Bates’ presentation (Bates, 1994) of Fodor’s nine criteria of modularity (ironically Bates is a skeptic on the subject). The information-processing criteria are: encapsulation (we cannot interfere with the functioning of a module), unconsciousness, speed (that’s the point of the module), shallow outputs (we have no idea of the intermediate steps), and obligatory firing (a module generates predetermined outputs for predetermined inputs). The biological criteria that distinguish them from learned habits are: ontogenetic universals (they develop in characteristic sequence), localization (they use dedicated neural systems), and pathological universals (modules have characteristic pathologies across populations). Finally, modularity’s most important property is its domain specificity.</p>
<br/>
<p class="atx1"><b>Books on the physical brain:</b> For the hierarchy reptilian/limbic/neocortical, see causal descriptions in Ratey (2001), Ramachandran and Blakeslee (1998), Carter (1999), Carter (2002), Conlan (1999), Lewis, Amini, and Lannon (2000), and Goleman (1995).</p>
<br/>
<p class="atx1"><b>Emotional Brain:</b> Damasio (1994) and LeDoux (1998). Bechara, Damasio, Damasion, and Tranel (1994) show the degradation of the risk-avoidance behavior of patients with damage in their ventromedial frontal cortex, a part of the brain that links us to our emotions. Emotions seem to play a critical role both ways. For the new field of neuroeconomics, see discussions in Glimcher (2002) and Camerer, Loewenstein and Prelec (2003).</p>
<br/>
<p class="atx1"><b>Sensitivity to losses:</b> Note that losses matter more than gains, but you become rapidly desensitized to them (a loss of $10,000 is better than ten losses of $1,000). Gains matter less than losses, and large gains even less (ten gains of $1,000 are better than one gain of $10,000).</p>
<br/>
<p class="atx1"><b>Hedonic treadmill:</b> My late friend Jimmy Powers used to go out of his way to show me very wealthy investment bankers acting miserably after a bad day. How good is all this wealth for them if they adjust to it to such a point that a single bad day can annihilate the effect of all these past successes? If things do not accumulate well then it follows that humans should follow a different set of strategies. This “resetting”shows the link to prospect theory.</p>
<br/>
<p class="atx1"><b>Debate:</b> Gigerenzer (1996), Kahneman and Tversky (1996), and Stanovich and West (2000). The evolutionary theorists are deemed to hold a Panglossian view: Evolution solves everything. Strangely, the debate is bitter not because of large divergences of opinions but because of small ones. <em>Simple Heuristics That Make Us Smart</em> is the title of a compilation of articles by Gigerenzer and his peers (Gigerenzer, 2000). See also Gigerenzer, Czerlinski and Martignon (2002).</p>
<br/>
<p class="atx1"><b>Medical example:</b> Bennett (1998). It is also discussed in Gigerenzer, Czerlinski and Martignon (2002).The heuristics and biases catalogue it as the base rate fallacy. The evolutionary theorists split into domain general (unconditional probability) as opposed to domain specific (conditional).</p>
<br/>
<p class="atx1"><b>Behavioral finance:</b> See Schleifer (2000) and Shefrin (2000) for a review. See also Thaler (1994b) and the original Thaler (1994a).</p>
<br/>
<p class="atx1"><b>Domain-specific adaptations:</b> Our lungs are a domain-specific adaptation meant to extract oxygen from the air and deposit it into our blood; they are not meant to circulate blood. For evolutionary psychologists the same applies to psychological adaptations.</p>
<br/>
<p class="atx1"><b>Opaque process:</b> For psychologists in the heuristics and biases tradition, System 1 is opaque, that is, not self-aware. This resembles the encapsulation and unconsciousness of modules discussed earlier.</p>
<br/>
<p class="atx1"><b>Flow:</b> See Csikszentmihalyi (1993) and Csikszentmihalyi (1998). I am quoting both to be safe but I don’t know if there are differences between the books: The author seems to rewrite the same global idea in different ways.</p>
<br/>
<p class="atx1"><b>Underestimation of possible outcomes:</b> Hilton (2003).</p>
<br/>
<p class="atx1"><b>The neurobiology of eye contact:</b> Ramachandran and Blakeslee (1998) on the visual centers that project to the amygdala: “Scientists recording cell responses in the amygdala found that, in addition to responding to facial expressions and emotions, the cells also respond to the direction of eye gaze. For instance, one cell may fire if another person is looking directly at you, whereas a neighboring cell will fire only if that person’s gaze is averted by a fraction of an inch. Still other cells fire when the gaze is way off to the left or the right. This phenomenon is not surprising given the important role that gaze direction plays in primate social communications—the averted gaze of guilt, shame or embarrassment; the intense, direct gaze of a lover, or the threatening stare of an enemy.”</p>
<p class="imp"><small>CHAPTER 12</small></p>
<p class="atx1"><b>Pigeons in a box:</b> Skinner (1948).</p>
<br/>
<p class="atx1"><b>Illusion of knowledge:</b> Barber and Odean (2001) presents a discussion of the literature on the tendency to make a stronger inference than warranted by the data, which they call “Illusion of Knowledge.”</p>
<p class="imp"><small>CHAPTER 13</small></p>
<p class="atx1"><b>Arabic skeptics:</b> al-Ghaz<img alt="image" src="images/enta-bar.jpg"/>l<img alt="image" src="images/enti-bar.jpg"/> (1989).</p>
<br/>
<p class="atx1"><b>Rozan’s book:</b> Rozan (1999).</p>
<p class="atx1"><b>Mental accounting:</b> Thaler (1980) and Kahneman, Knetch and Thaler (1991).</p>
<p class="atx1"><b>Portfolio theory (alas):</b> Markowitz (1959).</p>
<br/>
<p class="atx1"><b>The conventional probability paradigm:</b> Most of the conventional discussions on probabilistic thought, especially in the philosophical literature, present minor variants of the same paradigm with the succession of the following historical contributions: Chevalier de Méré, Pascal, Cardano, De Moivre, Gauss, Bernouilli, Laplace, Bayes, von Mises, Carnap, Kolmogorov, Borel, De Finetti, Ramsey, etc. However, these concern the problems of <em>calculus</em> of probability, perhaps fraught with technical problems, but ones that are hair-splitting and, to be derogatory, <em>academic.</em> They are not of much concern in this book—because, inspite of my specialty, they do not seem to provide any remote usefulness for practical matters. For a review of these, I refer the reader to Gillies (2000),Von Plato (1994),Hacking (1990),or the more popular and immensely readable <em>Against the Gods</em> (Bernstein, 1996), itself drawing heavily on Florence Nightingale David (David, 1962). I recommend Bernstein’s <em>Against the Gods</em> as a readable presentation of the history of probabilistic thought in engineering and the applied hard sciences but completely disagree with its message on the measurability of risks in the social sciences.</p>
<p class="tx">I repeat the point: To philosophers operating in probability <em>per se,</em> the problem seems one of calculus. In this book the problem of probability is largely a matter of knowledge, not one of computation. I consider these computations a mere footnote to the subject. The real problem is: Where do we get the probability from? How do we change our beliefs? I have been working on the “gambling with the wrong dice” problem: It is far more important to figure out what dice we are using when gambling than to develop sophisticated computations of outcomes and run the risk of having, say, dice with nothing but 6s. In economics, for instance, we have very large models of risk calculations sitting on very rickety assumptions (actually, not rickety but plain wrong). They smoke us with math, but everything else is wrong. Getting the right assumptions may matter more than having a sophisticated model.</p>
<p class="tx">An interesting problem is the “value at risk” issue where people imagine that they have a way to understand the risk using “complicated mathematics” and running predictions on rare events—thinking that they were able from past data to observe the probability distributions. The most interesting behavioral aspect is that those who advocate it do not seem to have tested their past predicting record, another Meehl type of problem.</p>
<br/>
<p class="atx1"><b>Thinkers and philosophers of probability:</b> Perhaps the most insightful book ever written on the subject remains the great John Maynard Keynes’ <em>Treatise on Probability</em> (Keynes, 1989, 1920), which surprisingly has not collected dust—somehow everything we seem to discover appears to have been said in it (though, characteristic of Keynes, in a convoluted way). In the usual supplied lists of thinkers of probability, Shackle, who refined subjective probability, is often undeservedly absent (Shackle, 1973). Most authors also omit the relevant contributions of Isaac Levi on subjective probability and its links to belief (Levi, 1970), which should be required reading in that area (it is impenetrable but is worth the exercise). It is a shame because Isaac Levi is a probability <em>thinker</em> (as opposed to probability <em>calculator</em>). The epistemologist of probability Henry Kyburg (Kyburg, 1983) is also absent (too difficult to read).</p>
<p class="tx">One observation about philosophers as compared to scientists is that they do seem to work in a very heterogeneous and compartmented manner: Probability in philosophy is dealt with in different branches: logic, epistemology, rational choice, philosophy of mathematics, philosophy of science. It is surprising to see Nicholas Rescher delivering an insightful presidential address of the American Philosophical Association on the topic of luck (later published as a book called <em>Luck,</em> see Rescher, 1995) without discussing much of the problems in the philosophical and cognitive literature on probability.</p>
<br/>
<p class="atx1"><b>Problems with my message:</b> Note that many readers in the technical professions, say engineering, exhibited some difficulty seeing the connection between probability and belief and the importance of skepticism in risk management.</p>
<p class="imp"><small>CHAPTER 14</small></p>
<p class="atx1"><b>Stoicism:</b> Modern discussions in Becker (1998) and Banateanu (2001).</p>
<p class="imp"><small>POSTSCRIPT</small></p>
<p class="atx1"><b>Uncertainty and pleasure:</b> See Wilson, et. al. (2005) for the effect of randomness on the prolongation of positive hedonic states.</p>
<br/>
<p class="atx1"><b>Looks and success:</b> See (Shahami, et. al., 1993; Hosoda et. al., 1999). My friend Peter Bevelin wrote to me: “When I’m thinking about misjudgment of personalities I am always reminded of Sherlock Holmes in Arthur Conan Doyle’s <em>The Sign of Four.</em> “It is of the first importance not to allow your judgment to be biased by personal qualities. I assure you that the most winning woman I ever knew was hanged for poisoning three little children for their insurance-money, and the most repellent man of my acquaintance is a philanthropist who has spent nearly a quarter of a million upon the London poor.”</p>
<br/>
<p class="atx1"><b>Maximizing:</b> Psychology literature has focused on maximizing in terms of choice, not so much in these terms of actual optimization. I go beyond by looking at the activity of optimization in daily life. For a synthesis and review of the hedonic impact of maximizing and why “less is more,” see Schwartz (2003). See also Schwartz, et. al. (2002). For the causal link between unhappiness and the pursuit of material benefits, see Kasser (2002).</p>
<br/>
<p class="atx1"><b>Date of your death:</b> I owe this last point to Gerd Gigerenzer.</p>
<br/>
<p class="atx1"><b>Unpredictable behavior:</b> See Miller (2000) for the discussion of the point in biology. See also Lucas’s (1978) applications to a random monetary policy that thwarts expectations.</p></div>
</body></html>